{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55665382-13f6-45f6-9750-d1f792eade5a",
   "metadata": {},
   "source": [
    "# Model Name: Qwen/Qwen2.5-VL-7B-Instruct\n",
    "# Dataset: Mixed Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac85919-004a-420f-a363-5c47ddcdb179",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /mnt/home/gjenni/.local/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /mnt/home/gjenni/.local/lib/python3.12/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /mnt/home/gjenni/.local/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043b8437-1fa8-4c38-b483-8432f097915f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu124\n",
      "CUDA Available: True\n",
      "GPU Name: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7caa8306-1fce-4589-a480-a2f0532b01d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/gjenni-tmpdir-LXqnIL/pip-req-build-ls43mrue\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/gjenni-tmpdir-LXqnIL/pip-req-build-ls43mrue\n",
      "  Resolved https://github.com/huggingface/transformers to commit 2932f318a20d9e54cc7aea052e040164d85de7d6\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /mnt/home/gjenni/.local/lib/python3.12/site-packages (1.4.0.dev0)\n",
      "Requirement already satisfied: filelock in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: psutil in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: qwen-vl-utils==0.0.8 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from qwen-vl-utils[decord]==0.0.8) (0.0.8)\n",
      "Requirement already satisfied: av in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (14.1.0)\n",
      "Requirement already satisfied: packaging in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (24.1)\n",
      "Requirement already satisfied: pillow in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (10.4.0)\n",
      "Requirement already satisfied: requests in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (2.32.3)\n",
      "Requirement already satisfied: decord in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from qwen-vl-utils[decord]==0.0.8) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from decord->qwen-vl-utils[decord]==0.0.8) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers accelerate\n",
    "!pip install qwen-vl-utils[decord]==0.0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16949a33-b691-4d4d-9095-721bb2f8449c",
   "metadata": {},
   "source": [
    "### Load the model and processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80eb64af-0ca7-4cb1-8723-e8eaa40f9c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e300dc2c341485ab4d0b47d170f1af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Processor Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "\n",
    "# Load the model on the GPU\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct\", torch_dtype=torch.float16, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load the processor\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
    "\n",
    "print(\"Model and Processor Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8883d0-1993-4321-9dd3-1e69aa407cf5",
   "metadata": {},
   "source": [
    "## AND Case - Table Only Based Ground Truth\n",
    "\n",
    "### Single Inference Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc8f793-29e6-482b-ab7f-79728b612ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Prompt:\n",
      "\n",
      "Given the following building attributes:\n",
      "- Building ID: 3581560.0\n",
      "- Maximum roof slope: 51.01464222107296 degrees\n",
      "- Maximum roof height: 3.984000000000009 meters\n",
      "\n",
      "If the maximum roof slope is greater than or equal to 30 degrees AND the maximum roof height is greater than or equal to 4 meters, predict that the attic is used as a living space.\n",
      "\n",
      "**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\n",
      "\n",
      "Full Model Output:\n",
      "\n",
      "Given the following building attributes:\n",
      "- Building ID: 3581560.0\n",
      "- Maximum roof slope: 51.01464222107296 degrees\n",
      "- Maximum roof height: 3.984000000000009 meters\n",
      "\n",
      "If the maximum roof slope is greater than or equal to 30 degrees AND the maximum roof height is greater than or equal to 4 meters, predict that the attic is used as a living space.\n",
      "\n",
      "**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.** No\n",
      "Model final prediction: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/mixed_table/attic_ground_truths_combined.csv')\n",
    "\n",
    "# 2. Select the first row\n",
    "row = df.iloc[0]\n",
    "\n",
    "# 3. Create the prompt\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees AND the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "\n",
    "prompt = create_improved_prompt(row)\n",
    "\n",
    "\n",
    "print(\"Generated Prompt:\\n\")\n",
    "print(prompt)\n",
    "\n",
    "# 4. Perform inference\n",
    "inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Decode and just print\n",
    "prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "prediction = prediction.strip()\n",
    "\n",
    "# Print full model output to debug\n",
    "print(\"\\nFull Model Output:\\n\")\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "# After model prediction\n",
    "final_text = prediction.strip().lower()\n",
    "\n",
    "if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "    pred_value = 1\n",
    "elif \" no\" in final_text or final_text.endswith('no'):\n",
    "    pred_value = 0\n",
    "else:\n",
    "    pred_value = -1\n",
    "\n",
    "print(\"Model final prediction:\", pred_value)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217979da-5fa1-42b9-b24e-17785c412d8e",
   "metadata": {},
   "source": [
    "### Batch Inference Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e4b066-82f3-4415-8ab4-7ee1963a4d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on all rows: 100%|██████████| 745/745 [00:53<00:00, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All predictions saved successfully to: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/mixed_predictions_AND.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/mixed_table/attic_ground_truths_combined.csv')\n",
    "\n",
    "# 2. Create the improved prompt function\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees AND the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "# 3. Function to perform prediction for a given prompt\n",
    "def predict_attic_use(prompt):\n",
    "    inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "    prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    prediction = prediction.strip()\n",
    "\n",
    "    final_text = prediction.strip().lower()\n",
    "\n",
    "    if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "        return 1\n",
    "    elif \" no\" in final_text or final_text.endswith('no'):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  # unexpected case\n",
    "\n",
    "# 4. Inference for all rows\n",
    "predictions = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Running inference on all rows\"):\n",
    "    prompt = create_improved_prompt(row)\n",
    "    pred = predict_attic_use(prompt)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# 5. Add predictions to dataframe\n",
    "df['pred_AND'] = predictions\n",
    "\n",
    "# 6. Save the updated dataframe\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'mixed_predictions_AND.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ All predictions saved successfully to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519bdefb-8a4e-41d5-bce2-69af1b18a7cd",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9c1422-bfe7-4b16-a41c-4d4734d5bcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy: 0.9933\n",
      "\n",
      "🧮 Confusion Matrix (Numbers):\n",
      "[[573   5]\n",
      " [  0 167]]\n",
      "\n",
      "📄 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Used       1.00      0.99      1.00       578\n",
      "        Used       0.97      1.00      0.99       167\n",
      "\n",
      "    accuracy                           0.99       745\n",
      "   macro avg       0.99      1.00      0.99       745\n",
      "weighted avg       0.99      0.99      0.99       745\n",
      "\n",
      "\n",
      "✅ Confusion matrix plot saved successfully at: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix/conf_mat_mixed_AND.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/gjenni-tmpdir-LXqnIL/ipykernel_289918/495800850.py:40: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/gjenni-tmpdir-LXqnIL/ipykernel_289918/495800850.py:46: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(save_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the predictions CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/mixed_predictions_AND.csv')\n",
    "\n",
    "# 2. Define ground truth and model predictions\n",
    "y_true = df['GT_AND']\n",
    "y_pred = df['pred_AND']\n",
    "\n",
    "# 3. Calculate Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n✅ Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 4. Show Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\n🧮 Confusion Matrix (Numbers):\")\n",
    "print(cm)\n",
    "\n",
    "# 5. Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=[\"Not Used\", \"Used\"])\n",
    "print(\"\\n📄 Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# 4. Create figure\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "# 5. Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[\"Predicted Not Used\", \"Predicted Used\"],\n",
    "            yticklabels=[\"Actual Not Used\", \"Actual Used\"],\n",
    "            ax=ax)\n",
    "ax.set_title('🏠 Confusion Matrix for Attic Living Space Prediction')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "# 6. Tight Layout and Save\n",
    "plt.tight_layout()\n",
    "\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(output_dir, 'conf_mat_mixed_AND.png')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# 7. Close the figure AFTER saving\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n✅ Confusion matrix plot saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bc7d46-1786-45b8-8b24-22f30111c8d4",
   "metadata": {},
   "source": [
    "## OR Case - Table Only Based Ground Truth\n",
    "### Single Inference Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5b8b70e-3bd2-4852-9329-3b93621156cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Prompt:\n",
      "\n",
      "Given the following building attributes:\n",
      "- Building ID: 3583164.0\n",
      "- Maximum roof slope: 32.100303921658586 degrees\n",
      "- Maximum roof height: 2.8499999999999943 meters\n",
      "\n",
      "If the maximum roof slope is greater than or equal to 30 degrees OR the maximum roof height is greater than or equal to 4 meters, predict that the attic is used as a living space.\n",
      "\n",
      "**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\n",
      "\n",
      "Full Model Output:\n",
      "\n",
      "Given the following building attributes:\n",
      "- Building ID: 3583164.0\n",
      "- Maximum roof slope: 32.100303921658586 degrees\n",
      "- Maximum roof height: 2.8499999999999943 meters\n",
      "\n",
      "If the maximum roof slope is greater than or equal to 30 degrees OR the maximum roof height is greater than or equal to 4 meters, predict that the attic is used as a living space.\n",
      "\n",
      "**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.** Yes\n",
      "Model final prediction: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/mixed_table/attic_ground_truths_combined.csv')\n",
    "\n",
    "# 2. Select the first row\n",
    "row = df.iloc[28]\n",
    "\n",
    "# 3. Create the prompt\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees OR the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "\n",
    "prompt = create_improved_prompt(row)\n",
    "\n",
    "\n",
    "print(\"Generated Prompt:\\n\")\n",
    "print(prompt)\n",
    "\n",
    "# 4. Perform inference\n",
    "inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Decode and just print\n",
    "prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "prediction = prediction.strip()\n",
    "\n",
    "# Print full model output to debug\n",
    "print(\"\\nFull Model Output:\\n\")\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "# After model prediction\n",
    "final_text = prediction.strip().lower()\n",
    "\n",
    "if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "    pred_value = 1\n",
    "elif \" no\" in final_text or final_text.endswith('no'):\n",
    "    pred_value = 0\n",
    "else:\n",
    "    pred_value = -1\n",
    "\n",
    "print(\"Model final prediction:\", pred_value)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0283ef-d035-4fa2-9fee-dfaf1bf4c366",
   "metadata": {},
   "source": [
    "### Batch Inference Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c5bc04-dd10-40be-b698-b7317809cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on all rows: 100%|██████████| 745/745 [01:18<00:00,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All predictions saved successfully to: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/mixed_predictions_OR.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/mixed_table/attic_ground_truths_combined.csv')\n",
    "\n",
    "# 2. Create the improved prompt function\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees OR the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "# 3. Function to perform prediction for a given prompt\n",
    "def predict_attic_use(prompt):\n",
    "    inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "    prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    prediction = prediction.strip()\n",
    "\n",
    "    final_text = prediction.strip().lower()\n",
    "\n",
    "    if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "        return 1\n",
    "    elif \" no\" in final_text or final_text.endswith('no'):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  # unexpected case\n",
    "\n",
    "# 4. Inference for all rows\n",
    "predictions = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Running inference on all rows\"):\n",
    "    prompt = create_improved_prompt(row)\n",
    "    pred = predict_attic_use(prompt)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# 5. Add predictions to dataframe\n",
    "df['pred_OR'] = predictions\n",
    "\n",
    "# 6. Save the updated dataframe\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'mixed_predictions_OR.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ All predictions saved successfully to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77479c-98da-4dc2-b9df-465a4d994c02",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f48fb15-2838-47b9-b29d-864e85bca959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy: 0.9208\n",
      "\n",
      "🧮 Confusion Matrix (Numbers):\n",
      "[[356   4]\n",
      " [ 55 330]]\n",
      "\n",
      "📄 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Used       0.87      0.99      0.92       360\n",
      "        Used       0.99      0.86      0.92       385\n",
      "\n",
      "    accuracy                           0.92       745\n",
      "   macro avg       0.93      0.92      0.92       745\n",
      "weighted avg       0.93      0.92      0.92       745\n",
      "\n",
      "\n",
      "✅ Confusion matrix plot saved successfully at: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix/conf_mat_mixed_OR.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/gjenni-tmpdir-LXqnIL/ipykernel_289918/136847580.py:40: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/gjenni-tmpdir-LXqnIL/ipykernel_289918/136847580.py:46: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(save_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the predictions CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/mixed_predictions_OR.csv')\n",
    "\n",
    "# 2. Define ground truth and model predictions\n",
    "y_true = df['GT_OR']\n",
    "y_pred = df['pred_OR']\n",
    "\n",
    "# 3. Calculate Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n✅ Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 4. Show Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\n🧮 Confusion Matrix (Numbers):\")\n",
    "print(cm)\n",
    "\n",
    "# 5. Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=[\"Not Used\", \"Used\"])\n",
    "print(\"\\n📄 Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# 4. Create figure\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "# 5. Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[\"Predicted Not Used\", \"Predicted Used\"],\n",
    "            yticklabels=[\"Actual Not Used\", \"Actual Used\"],\n",
    "            ax=ax)\n",
    "ax.set_title('🏠 Confusion Matrix for Attic Living Space Prediction')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "# 6. Tight Layout and Save\n",
    "plt.tight_layout()\n",
    "\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(output_dir, 'conf_mat_mixed_OR.png')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# 7. Close the figure AFTER saving\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n✅ Confusion matrix plot saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c120f-5d21-4708-960a-483445d20859",
   "metadata": {},
   "source": [
    "## AND Case - Combined Image and Table Only Based Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e14d7-b007-46b2-bba6-b1e89c02d236",
   "metadata": {},
   "source": [
    "### Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4170c16d-d400-48c8-9d73-ffbab9815cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on all rows: 100%|██████████| 745/745 [01:56<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All predictions saved successfully to: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/mixed_predictions_table_real_AND.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/mixed_table/attic_GT_IMG_AND_and_GT_IMG_OR_Labels.csv')\n",
    "\n",
    "# 2. Create the improved prompt function\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees AND the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "# 3. Function to perform prediction for a given prompt\n",
    "def predict_attic_use(prompt):\n",
    "    inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "    prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    prediction = prediction.strip()\n",
    "\n",
    "    final_text = prediction.strip().lower()\n",
    "\n",
    "    if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "        return 1\n",
    "    elif \" no\" in final_text or final_text.endswith('no'):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  # unexpected case\n",
    "\n",
    "# 4. Inference for all rows\n",
    "predictions = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Running inference on all rows\"):\n",
    "    prompt = create_improved_prompt(row)\n",
    "    pred = predict_attic_use(prompt)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# 5. Add predictions to dataframe\n",
    "df['pred_AND'] = predictions\n",
    "\n",
    "# 6. Save the updated dataframe\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'mixed_predictions_table_real_AND.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ All predictions saved successfully to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5882c3d3-254e-4f09-98de-0f7b10381eae",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88dec70e-5170-4695-a577-902dd59e829d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy: 0.7396\n",
      "\n",
      "🧮 Confusion Matrix (Numbers):\n",
      "[[380   1]\n",
      " [193 171]]\n",
      "\n",
      "📄 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Used       0.66      1.00      0.80       381\n",
      "        Used       0.99      0.47      0.64       364\n",
      "\n",
      "    accuracy                           0.74       745\n",
      "   macro avg       0.83      0.73      0.72       745\n",
      "weighted avg       0.82      0.74      0.72       745\n",
      "\n",
      "\n",
      "✅ Confusion matrix plot saved successfully at: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix/conf_mat_mixed_table_real_GT_AND.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/gjenni-tmpdir-W1CWup/ipykernel_172641/4261403669.py:40: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/gjenni-tmpdir-W1CWup/ipykernel_172641/4261403669.py:46: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(save_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the predictions CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/mixed_predictions_table_real_AND.csv')\n",
    "\n",
    "# 2. Define ground truth and model predictions\n",
    "y_true = df['GT_IMG_AND']\n",
    "y_pred = df['pred_AND']\n",
    "\n",
    "# 3. Calculate Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n✅ Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 4. Show Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\n🧮 Confusion Matrix (Numbers):\")\n",
    "print(cm)\n",
    "\n",
    "# 5. Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=[\"Not Used\", \"Used\"])\n",
    "print(\"\\n📄 Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# 4. Create figure\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "# 5. Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[\"Predicted Not Used\", \"Predicted Used\"],\n",
    "            yticklabels=[\"Actual Not Used\", \"Actual Used\"],\n",
    "            ax=ax)\n",
    "ax.set_title('🏠 Confusion Matrix for Attic Living Space Prediction')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "# 6. Tight Layout and Save\n",
    "plt.tight_layout()\n",
    "\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(output_dir, 'conf_mat_mixed_table_real_GT_AND.png')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# 7. Close the figure AFTER saving\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n✅ Confusion matrix plot saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2616b-0688-43b2-acd1-ea8e8291e475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e9d5c9-81b9-448e-86ec-c5da5aa8fc3d",
   "metadata": {},
   "source": [
    "## OR Case - Combined Image and Table Only Based Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6d4fbe-361b-4bbb-8b65-ddb609a8982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc836a56-1395-4a6a-8cbb-fdde9b862867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on all rows: 100%|██████████| 745/745 [02:58<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All predictions saved successfully to: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/mixed_predictions_table_real_OR.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/mixed_table/attic_GT_IMG_AND_and_GT_IMG_OR_Labels.csv')\n",
    "\n",
    "# 2. Create the improved prompt function\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees OR the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "# 3. Function to perform prediction for a given prompt\n",
    "def predict_attic_use(prompt):\n",
    "    inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "    prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    prediction = prediction.strip()\n",
    "\n",
    "    final_text = prediction.strip().lower()\n",
    "\n",
    "    if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "        return 1\n",
    "    elif \" no\" in final_text or final_text.endswith('no'):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  # unexpected case\n",
    "\n",
    "# 4. Inference for all rows\n",
    "predictions = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Running inference on all rows\"):\n",
    "    prompt = create_improved_prompt(row)\n",
    "    pred = predict_attic_use(prompt)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# 5. Add predictions to dataframe\n",
    "df['pred_OR'] = predictions\n",
    "\n",
    "# 6. Save the updated dataframe\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'mixed_predictions_table_real_OR.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ All predictions saved successfully to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a266b-5617-41fc-b315-1cd76ace26e6",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19640f53-5873-4596-a546-77c680b68aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy: 0.8161\n",
      "\n",
      "🧮 Confusion Matrix (Numbers):\n",
      "[[275   2]\n",
      " [135 333]]\n",
      "\n",
      "📄 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Used       0.67      0.99      0.80       277\n",
      "        Used       0.99      0.71      0.83       468\n",
      "\n",
      "    accuracy                           0.82       745\n",
      "   macro avg       0.83      0.85      0.81       745\n",
      "weighted avg       0.87      0.82      0.82       745\n",
      "\n",
      "\n",
      "✅ Confusion matrix plot saved successfully at: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix/conf_mat_mixed_table_real_GT_OR.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/gjenni-tmpdir-W1CWup/ipykernel_172641/372786938.py:40: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/gjenni-tmpdir-W1CWup/ipykernel_172641/372786938.py:46: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(save_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the predictions CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/mixed_predictions_table_real_OR.csv')\n",
    "\n",
    "# 2. Define ground truth and model predictions\n",
    "y_true = df['GT_IMG_OR']\n",
    "y_pred = df['pred_OR']\n",
    "\n",
    "# 3. Calculate Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n✅ Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 4. Show Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\n🧮 Confusion Matrix (Numbers):\")\n",
    "print(cm)\n",
    "\n",
    "# 5. Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=[\"Not Used\", \"Used\"])\n",
    "print(\"\\n📄 Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# 4. Create figure\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "# 5. Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[\"Predicted Not Used\", \"Predicted Used\"],\n",
    "            yticklabels=[\"Actual Not Used\", \"Actual Used\"],\n",
    "            ax=ax)\n",
    "ax.set_title('🏠 Confusion Matrix for Attic Living Space Prediction')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "# 6. Tight Layout and Save\n",
    "plt.tight_layout()\n",
    "\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(output_dir, 'conf_mat_mixed_table_real_GT_OR.png')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# 7. Close the figure AFTER saving\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n✅ Confusion matrix plot saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e4418-509a-4906-afae-cf2ff75eebae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80086833-564f-4d17-92ad-c96ddadf8bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
