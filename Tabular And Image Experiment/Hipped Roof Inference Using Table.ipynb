{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3b4b4c-0dab-4617-9815-7cf6e65651cc",
   "metadata": {},
   "source": [
    "# Model Name: Qwen/Qwen2.5-VL-7B-Instruct\n",
    "# Dataset: Hipped Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67080da6-9c38-4420-bea3-aa01232e2947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /mnt/home/gjenni/.local/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /mnt/home/gjenni/.local/lib/python3.12/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /mnt/home/gjenni/.local/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52a926d-8165-4c31-a42b-a8800837d275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu124\n",
      "CUDA Available: True\n",
      "GPU Name: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "262cf8de-bfb4-4399-a094-cc52a3a64d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/gjenni-tmpdir-LXqnIL/pip-req-build-9zudtvpf\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/gjenni-tmpdir-LXqnIL/pip-req-build-9zudtvpf\n",
      "  Resolved https://github.com/huggingface/transformers to commit 2932f318a20d9e54cc7aea052e040164d85de7d6\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /mnt/home/gjenni/.local/lib/python3.12/site-packages (1.4.0.dev0)\n",
      "Requirement already satisfied: filelock in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: psutil in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->transformers==4.52.0.dev0) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: qwen-vl-utils==0.0.8 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from qwen-vl-utils[decord]==0.0.8) (0.0.8)\n",
      "Requirement already satisfied: av in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (14.1.0)\n",
      "Requirement already satisfied: packaging in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (24.1)\n",
      "Requirement already satisfied: pillow in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (10.4.0)\n",
      "Requirement already satisfied: requests in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (2.32.3)\n",
      "Requirement already satisfied: decord in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from qwen-vl-utils[decord]==0.0.8) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /mnt/home/gjenni/.local/lib/python3.12/site-packages (from decord->qwen-vl-utils[decord]==0.0.8) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/apps/modules/conda/python3.12.0/lib/python3.12/site-packages (from requests->qwen-vl-utils==0.0.8->qwen-vl-utils[decord]==0.0.8) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers accelerate\n",
    "!pip install qwen-vl-utils[decord]==0.0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20890d8f-ef66-476f-b097-d7ce7070db2f",
   "metadata": {},
   "source": [
    "### Load the model and processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2565c5ad-dd85-46f7-8ac8-ec86ba743274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7104c6a524b4692aacdcd27b44b128a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Processor Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "\n",
    "# Load the model on the GPU\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct\", torch_dtype=torch.float16, device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load the processor\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
    "\n",
    "print(\"Model and Processor Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc13b8-da2c-458d-9f88-1cef1800752d",
   "metadata": {},
   "source": [
    "## AND Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a866696-04d0-4ad6-8a8a-b180c3856d29",
   "metadata": {},
   "source": [
    "### Single Inference Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70786035-18d7-4cb4-8227-eb578632e15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Prompt:\n",
      "\n",
      "Given the following building attributes:\n",
      "- Building ID: 3581635.0\n",
      "- Maximum roof slope: 33.02212920656211 degrees\n",
      "- Maximum roof height: 5.129999999999996 meters\n",
      "\n",
      "If the maximum roof slope is greater than or equal to 30 degrees AND the maximum roof height is greater than or equal to 4 meters, predict that the attic is used as a living space.\n",
      "\n",
      "**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\n",
      "\n",
      "Full Model Output:\n",
      "\n",
      "Given the following building attributes:\n",
      "- Building ID: 3581635.0\n",
      "- Maximum roof slope: 33.02212920656211 degrees\n",
      "- Maximum roof height: 5.129999999999996 meters\n",
      "\n",
      "If the maximum roof slope is greater than or equal to 30 degrees AND the maximum roof height is greater than or equal to 4 meters, predict that the attic is used as a living space.\n",
      "\n",
      "**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.** Yes\n",
      "Model final prediction: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/hipped_table/attic_ground_truths_hipped_3200.csv')\n",
    "\n",
    "# 2. Select the first row\n",
    "row = df.iloc[0]\n",
    "\n",
    "# 3. Create the prompt\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees AND the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "\n",
    "prompt = create_improved_prompt(row)\n",
    "\n",
    "\n",
    "print(\"Generated Prompt:\\n\")\n",
    "print(prompt)\n",
    "\n",
    "# 4. Perform inference\n",
    "inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Decode and just print\n",
    "prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "prediction = prediction.strip()\n",
    "\n",
    "# Print full model output to debug\n",
    "print(\"\\nFull Model Output:\\n\")\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "# After model prediction\n",
    "final_text = prediction.strip().lower()\n",
    "\n",
    "if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "    pred_value = 1\n",
    "elif \" no\" in final_text or final_text.endswith('no'):\n",
    "    pred_value = 0\n",
    "else:\n",
    "    pred_value = -1\n",
    "\n",
    "print(\"Model final prediction:\", pred_value)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c6856-939b-4851-ab1f-119d6a6789dd",
   "metadata": {},
   "source": [
    "### Batch Inference Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc9a906-49ae-486c-8d35-77a95d3d44ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on all rows: 100%|██████████| 370/370 [00:25<00:00, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All predictions saved successfully to: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/hipped_predictions_AND.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/hipped_table/attic_ground_truths_hipped_3200.csv')\n",
    "\n",
    "# 2. Create the improved prompt function\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees AND the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "# 3. Function to perform prediction for a given prompt\n",
    "def predict_attic_use(prompt):\n",
    "    inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "    prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    prediction = prediction.strip()\n",
    "\n",
    "    final_text = prediction.strip().lower()\n",
    "\n",
    "    if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "        return 1\n",
    "    elif \" no\" in final_text or final_text.endswith('no'):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  # unexpected case\n",
    "\n",
    "# 4. Inference for all rows\n",
    "predictions = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Running inference on all rows\"):\n",
    "    prompt = create_improved_prompt(row)\n",
    "    pred = predict_attic_use(prompt)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# 5. Add predictions to dataframe\n",
    "df['pred_AND'] = predictions\n",
    "\n",
    "# 6. Save the updated dataframe\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'hipped_predictions_AND.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ All predictions saved successfully to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75608c-1a5d-4b68-829d-7fe8bfd9fabc",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c9234c-6448-4795-bc7d-4c270875291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy: 0.9838\n",
      "\n",
      "🧮 Confusion Matrix (Numbers):\n",
      "[[290   6]\n",
      " [  0  74]]\n",
      "\n",
      "📄 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Used       1.00      0.98      0.99       296\n",
      "        Used       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.98       370\n",
      "   macro avg       0.96      0.99      0.98       370\n",
      "weighted avg       0.98      0.98      0.98       370\n",
      "\n",
      "\n",
      "✅ Confusion matrix plot saved successfully at: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix/conf_mat_hipped_AND.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/gjenni-tmpdir-LXqnIL/ipykernel_288104/3027040860.py:40: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/gjenni-tmpdir-LXqnIL/ipykernel_288104/3027040860.py:46: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(save_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the predictions CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/hipped_predictions_AND.csv')\n",
    "\n",
    "# 2. Define ground truth and model predictions\n",
    "y_true = df['GT_AND']\n",
    "y_pred = df['pred_AND']\n",
    "\n",
    "# 3. Calculate Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n✅ Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 4. Show Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\n🧮 Confusion Matrix (Numbers):\")\n",
    "print(cm)\n",
    "\n",
    "# 5. Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=[\"Not Used\", \"Used\"])\n",
    "print(\"\\n📄 Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# 4. Create figure\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "# 5. Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[\"Predicted Not Used\", \"Predicted Used\"],\n",
    "            yticklabels=[\"Actual Not Used\", \"Actual Used\"],\n",
    "            ax=ax)\n",
    "ax.set_title('🏠 Confusion Matrix for Attic Living Space Prediction')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "# 6. Tight Layout and Save\n",
    "plt.tight_layout()\n",
    "\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(output_dir, 'conf_mat_hipped_AND.png')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# 7. Close the figure AFTER saving\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n✅ Confusion matrix plot saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d72985-a45d-49e7-b517-f3b201ac17d8",
   "metadata": {},
   "source": [
    "## OR Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa0f1af-9182-4c8a-a79c-518c03b0339a",
   "metadata": {},
   "source": [
    "### Single Inference Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b4ba9b8-08bf-48e7-afa6-38009e63e08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Prompt:\n",
      "\n",
      "Given the following building attributes:\n",
      "- Building ID: 3585384.0\n",
      "- Maximum roof slope: 21.206023565427174 degrees\n",
      "- Maximum roof height: 5.239000000000004 meters\n",
      "\n",
      "If the maximum roof slope is greater than or equal to 30 degrees OR the maximum roof height is greater than or equal to 4 meters, predict that the attic is used as a living space.\n",
      "\n",
      "**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\n",
      "\n",
      "Full Model Output:\n",
      "\n",
      "Given the following building attributes:\n",
      "- Building ID: 3585384.0\n",
      "- Maximum roof slope: 21.206023565427174 degrees\n",
      "- Maximum roof height: 5.239000000000004 meters\n",
      "\n",
      "If the maximum roof slope is greater than or equal to 30 degrees OR the maximum roof height is greater than or equal to 4 meters, predict that the attic is used as a living space.\n",
      "\n",
      "**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.** No\n",
      "\n",
      "Based on the given attributes:\n",
      "\n",
      "- The\n",
      "Model final prediction: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/hipped_table/attic_ground_truths_hipped_3200.csv')\n",
    "\n",
    "# 2. Select the first row\n",
    "row = df.iloc[28]\n",
    "\n",
    "# 3. Create the prompt\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees OR the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "\n",
    "prompt = create_improved_prompt(row)\n",
    "\n",
    "\n",
    "print(\"Generated Prompt:\\n\")\n",
    "print(prompt)\n",
    "\n",
    "# 4. Perform inference\n",
    "inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Decode and just print\n",
    "prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "prediction = prediction.strip()\n",
    "\n",
    "# Print full model output to debug\n",
    "print(\"\\nFull Model Output:\\n\")\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "# After model prediction\n",
    "final_text = prediction.strip().lower()\n",
    "\n",
    "if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "    pred_value = 1\n",
    "elif \" no\" in final_text or final_text.endswith('no'):\n",
    "    pred_value = 0\n",
    "else:\n",
    "    pred_value = -1\n",
    "\n",
    "print(\"Model final prediction:\", pred_value)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d404e-b501-4091-a363-fe496900bbf9",
   "metadata": {},
   "source": [
    "### Batch Inference Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "859fadb4-4fb5-48f5-b0fd-f2a825c75e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on all rows: 100%|██████████| 370/370 [00:41<00:00,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All predictions saved successfully to: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/hipped_predictions_OR.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/hipped_table/attic_ground_truths_hipped_3200.csv')\n",
    "\n",
    "# 2. Create the improved prompt function\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees OR the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "# 3. Function to perform prediction for a given prompt\n",
    "def predict_attic_use(prompt):\n",
    "    inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "    prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    prediction = prediction.strip()\n",
    "\n",
    "    final_text = prediction.strip().lower()\n",
    "\n",
    "    if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "        return 1\n",
    "    elif \" no\" in final_text or final_text.endswith('no'):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  # unexpected case\n",
    "\n",
    "# 4. Inference for all rows\n",
    "predictions = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Running inference on all rows\"):\n",
    "    prompt = create_improved_prompt(row)\n",
    "    pred = predict_attic_use(prompt)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# 5. Add predictions to dataframe\n",
    "df['pred_OR'] = predictions\n",
    "\n",
    "# 6. Save the updated dataframe\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'hipped_predictions_OR.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ All predictions saved successfully to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a6099b-a80f-4bd6-9f38-fac67469a981",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0feff2bc-1d5c-4380-84c2-f52b92497168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy: 0.9405\n",
      "\n",
      "🧮 Confusion Matrix (Numbers):\n",
      "[[227   3]\n",
      " [ 19 121]]\n",
      "\n",
      "📄 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Used       0.92      0.99      0.95       230\n",
      "        Used       0.98      0.86      0.92       140\n",
      "\n",
      "    accuracy                           0.94       370\n",
      "   macro avg       0.95      0.93      0.94       370\n",
      "weighted avg       0.94      0.94      0.94       370\n",
      "\n",
      "\n",
      "✅ Confusion matrix plot saved successfully at: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix/conf_mat_hipped_OR.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/gjenni-tmpdir-LXqnIL/ipykernel_288104/2569423513.py:40: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/gjenni-tmpdir-LXqnIL/ipykernel_288104/2569423513.py:46: UserWarning: Glyph 127968 (\\N{HOUSE BUILDING}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(save_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the predictions CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/hipped_predictions_OR.csv')\n",
    "\n",
    "# 2. Define ground truth and model predictions\n",
    "y_true = df['GT_OR']\n",
    "y_pred = df['pred_OR']\n",
    "\n",
    "# 3. Calculate Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n✅ Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 4. Show Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\n🧮 Confusion Matrix (Numbers):\")\n",
    "print(cm)\n",
    "\n",
    "# 5. Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=[\"Not Used\", \"Used\"])\n",
    "print(\"\\n📄 Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# 4. Create figure\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "# 5. Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[\"Predicted Not Used\", \"Predicted Used\"],\n",
    "            yticklabels=[\"Actual Not Used\", \"Actual Used\"],\n",
    "            ax=ax)\n",
    "ax.set_title('🏠 Confusion Matrix for Attic Living Space Prediction')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "# 6. Tight Layout and Save\n",
    "plt.tight_layout()\n",
    "\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(output_dir, 'conf_mat_hipped_OR.png')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# 7. Close the figure AFTER saving\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n✅ Confusion matrix plot saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7f399-602d-48bd-b815-bdd263a974ae",
   "metadata": {},
   "source": [
    "## AND Case - Combined Image and Table Only Based Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29af531f-14d3-4035-b0d4-3201bc7e0960",
   "metadata": {},
   "source": [
    "### Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680dc02d-3d4c-477b-b86e-e2a61ea96e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on all rows: 100%|██████████| 370/370 [00:25<00:00, 14.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All predictions saved successfully to: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/hipped_predictions_table_real_AND.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/hipped_table/attic_ground_truths_hipped_3200_GT_IMG.csv')\n",
    "\n",
    "# 2. Create the improved prompt function\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees AND the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "# 3. Function to perform prediction for a given prompt\n",
    "def predict_attic_use(prompt):\n",
    "    inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "    prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    prediction = prediction.strip()\n",
    "\n",
    "    final_text = prediction.strip().lower()\n",
    "\n",
    "    if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "        return 1\n",
    "    elif \" no\" in final_text or final_text.endswith('no'):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  # unexpected case\n",
    "\n",
    "# 4. Inference for all rows\n",
    "predictions = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Running inference on all rows\"):\n",
    "    prompt = create_improved_prompt(row)\n",
    "    pred = predict_attic_use(prompt)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# 5. Add predictions to dataframe\n",
    "df['pred_AND'] = predictions\n",
    "\n",
    "# 6. Save the updated dataframe\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'hipped_predictions_table_real_AND.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ All predictions saved successfully to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29093dfd-8c87-41b1-acca-067c952fbe84",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795e928c-bc16-4232-80ae-11b676ea5fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy: 0.7432\n",
      "\n",
      "🧮 Confusion Matrix (Numbers):\n",
      "[[197   1]\n",
      " [ 94  78]]\n",
      "\n",
      "📄 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Used       0.68      0.99      0.81       198\n",
      "        Used       0.99      0.45      0.62       172\n",
      "\n",
      "    accuracy                           0.74       370\n",
      "   macro avg       0.83      0.72      0.71       370\n",
      "weighted avg       0.82      0.74      0.72       370\n",
      "\n",
      "\n",
      "✅ Confusion matrix plot saved successfully at: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix/conf_mat_hipped_table_real_GT_AND.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the predictions CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/hipped_predictions_table_real_AND.csv')\n",
    "\n",
    "# 2. Define ground truth and model predictions\n",
    "y_true = df['GT_IMG_AND']\n",
    "y_pred = df['pred_AND']\n",
    "\n",
    "# 3. Calculate Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n✅ Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 4. Show Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\n🧮 Confusion Matrix (Numbers):\")\n",
    "print(cm)\n",
    "\n",
    "# 5. Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=[\"Not Used\", \"Used\"])\n",
    "print(\"\\n📄 Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# 4. Create figure\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "# 5. Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[\"Predicted Not Used\", \"Predicted Used\"],\n",
    "            yticklabels=[\"Actual Not Used\", \"Actual Used\"],\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "# 6. Tight Layout and Save\n",
    "plt.tight_layout()\n",
    "\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(output_dir, 'conf_mat_hipped_table_real_GT_AND.png')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# 7. Close the figure AFTER saving\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n✅ Confusion matrix plot saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137cba09-c589-44a9-bd77-dde0b6432a67",
   "metadata": {},
   "source": [
    "## OR Case - Combined Image and Table Only Based Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af804818-1de7-40d3-93d1-f0d65e9324cf",
   "metadata": {},
   "source": [
    "### Batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f83adf9-4c62-49ac-9c13-fb9b5a45fcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on all rows: 100%|██████████| 370/370 [00:41<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All predictions saved successfully to: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/hipped_predictions_table_real_OR.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# 1. Load the CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/data/tabular_data/hipped_table/attic_ground_truths_hipped_3200_GT_IMG.csv')\n",
    "\n",
    "# 2. Create the improved prompt function\n",
    "def create_improved_prompt(row):\n",
    "    return (\n",
    "        f\"Given the following building attributes:\\n\"\n",
    "        f\"- Building ID: {row['gid']}\\n\"\n",
    "        f\"- Maximum roof slope: {row['slope_max']} degrees\\n\"\n",
    "        f\"- Maximum roof height: {row['roof_height_max']} meters\\n\\n\"\n",
    "        \"If the maximum roof slope is greater than or equal to 30 degrees OR the maximum roof height is greater than or equal to 4 meters, \"\n",
    "        \"predict that the attic is used as a living space.\\n\\n\"\n",
    "        \"**At the beginning of your response, output only 'Yes' or 'No' on a new line. Do not repeat the input. Do not explain.**\"\n",
    "    )\n",
    "\n",
    "# 3. Function to perform prediction for a given prompt\n",
    "def predict_attic_use(prompt):\n",
    "    inputs = processor(text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "    prediction = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    prediction = prediction.strip()\n",
    "\n",
    "    final_text = prediction.strip().lower()\n",
    "\n",
    "    if \" yes\" in final_text or final_text.endswith('yes'):\n",
    "        return 1\n",
    "    elif \" no\" in final_text or final_text.endswith('no'):\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  # unexpected case\n",
    "\n",
    "# 4. Inference for all rows\n",
    "predictions = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Running inference on all rows\"):\n",
    "    prompt = create_improved_prompt(row)\n",
    "    pred = predict_attic_use(prompt)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# 5. Add predictions to dataframe\n",
    "df['pred_OR'] = predictions\n",
    "\n",
    "# 6. Save the updated dataframe\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'hipped_predictions_table_real_OR.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ All predictions saved successfully to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b681a-679f-4572-a2cf-2bf0f251fb09",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959a460f-e54a-4c25-b08e-2e513ef80c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy: 0.7973\n",
      "\n",
      "🧮 Confusion Matrix (Numbers):\n",
      "[[171   1]\n",
      " [ 74 124]]\n",
      "\n",
      "📄 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Used       0.70      0.99      0.82       172\n",
      "        Used       0.99      0.63      0.77       198\n",
      "\n",
      "    accuracy                           0.80       370\n",
      "   macro avg       0.84      0.81      0.79       370\n",
      "weighted avg       0.86      0.80      0.79       370\n",
      "\n",
      "\n",
      "✅ Confusion matrix plot saved successfully at: /mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix/conf_mat_hipped_table_real_GT_OR.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the predictions CSV\n",
    "df = pd.read_csv('/mnt/data/oe215/env/guna/tabular_image_inference/outputs/predictions/hipped_predictions_table_real_OR.csv')\n",
    "\n",
    "# 2. Define ground truth and model predictions\n",
    "y_true = df['GT_IMG_OR']\n",
    "y_pred = df['pred_OR']\n",
    "\n",
    "# 3. Calculate Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n✅ Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 4. Show Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\n🧮 Confusion Matrix (Numbers):\")\n",
    "print(cm)\n",
    "\n",
    "# 5. Classification Report\n",
    "report = classification_report(y_true, y_pred, target_names=[\"Not Used\", \"Used\"])\n",
    "print(\"\\n📄 Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# 4. Create figure\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "# 5. Plot Confusion Matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[\"Predicted Not Used\", \"Predicted Used\"],\n",
    "            yticklabels=[\"Actual Not Used\", \"Actual Used\"],\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "# 6. Tight Layout and Save\n",
    "plt.tight_layout()\n",
    "\n",
    "output_dir = '/mnt/data/oe215/env/guna/tabular_image_inference/outputs/evaluations/confusion_matrix'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(output_dir, 'conf_mat_hipped_table_real_GT_OR.png')\n",
    "plt.savefig(save_path)\n",
    "\n",
    "# 7. Close the figure AFTER saving\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n✅ Confusion matrix plot saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f2ca71-c9d7-4db9-9bec-80dd81aea515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
